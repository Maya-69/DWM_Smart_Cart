================================================================================
                        SMARTCART - AI-POWERED E-COMMERCE 
                      RECOMMENDATION SYSTEM PROJECT DOCUMENTATION
                    DATA WAREHOUSE & MINING (DWM) PERSPECTIVE
                              UPDATED: OCTOBER 29, 2025
================================================================================

PROJECT OVERVIEW
================================================================================
SmartCart is an intelligent e-commerce recommendation system that uses Machine 
Learning algorithms to suggest products based on real grocery shopping patterns. 
The system analyzes 38,765 real-world transactions to discover product 
associations, segment customers, predict demographics, and provide personalized 
recommendations to users.

PROJECT TYPE: Full-Stack AI/ML Application with Data Mining & Warehousing
DOMAIN: E-commerce, Grocery Shopping, Market Basket Analysis
MAIN FOCUS: Association Rule Mining, Customer Segmentation, Classification


================================================================================
                              TECH STACK BREAKDOWN
================================================================================

FRONTEND TECHNOLOGIES
─────────────────────
1. React (v18.3.1)
   - Purpose: Build dynamic, responsive user interface
   - Why: Component-based architecture for reusable UI elements
   - How it works: Virtual DOM updates only changed elements efficiently

2. Lucide-React (v0.263.1)
   - Purpose: Modern icon library for UI
   - Usage: Shopping cart, search, brain icons, analytics icons

3. ReactFlow (v11.11.4)
   - Purpose: Hierarchical graph visualization
   - Usage: Display product association trees with multiple levels

4. CSS3
   - Custom styling with gradients, animations, and responsive design
   - Interactive AI insights dashboard

BACKEND TECHNOLOGIES
────────────────────
1. Python 3.x
   - Core programming language
   - Why: Rich ecosystem for ML/AI and data processing

2. Flask
   - Purpose: RESTful API server
   - Why: Lightweight, easy to integrate with Python ML libraries
   - Key Endpoints:
     • GET  /api/products - Fetch all products
     • POST /api/recommendations - Get Apriori-based suggestions
     • POST /api/ai-insights - Generate decision trees
     • POST /api/recommendation-graph - Generate visual graphs
     • POST /api/predict-intent - Meal prediction AI
     • POST /api/predict-customer-segment - K-Means segmentation (NEW)
     • POST /api/predict-age-group - Naive Bayes age prediction (NEW)
     • GET  /api/model-status - Check ML model status

3. Flask-CORS
   - Purpose: Enable Cross-Origin Resource Sharing
   - Why: Allow React frontend (port 3000) to communicate with Flask (port 5000)

DATA STORAGE
────────────
SQLite (smartcart.db)
   - Purpose: Lightweight relational database
   - Why: No separate server needed, file-based, perfect for development
   - Tables:
     • products - Product catalog (169 unique items)
     • fact_transactions - Transaction fact table (38,765 records)
     • dim_customer - Customer dimension (5 customers)
     • dim_time - Time dimension (100 time records)
     • co_purchases - Pre-computed association patterns

MACHINE LEARNING LIBRARIES
───────────────────────────
1. Pandas
   - Data manipulation and analysis
   - Reading CSV datasets
   - GroupBy operations for transactions

2. NumPy
   - Numerical computations
   - Array operations
   - Statistical calculations

3. Scikit-learn (sklearn)
   - K-Means clustering for customer segmentation
   - StandardScaler for feature normalization
   - Silhouette analysis for cluster quality

4. SciPy
   - Statistical functions
   - Gaussian KDE for density plots

VISUALIZATION LIBRARIES
───────────────────────
1. Matplotlib
   - Primary plotting library
   - Generates comprehensive graphs

2. Seaborn
   - Statistical visualizations
   - Heatmaps, enhanced plots


================================================================================
                        DATA WAREHOUSE ARCHITECTURE
================================================================================

SCHEMA DESIGN: Star Schema (Ralph Kimball Methodology)
───────────────────────────────────────────────────────

Why Star Schema?
• Simple queries (fewer joins)
• Fast aggregations (OLAP operations)
• Easy to understand and maintain
• Optimized for analytical workloads

FACT TABLE: fact_transactions
──────────────────────────────
Purpose: Central table storing measurable business events (transactions)

Fields:
  • transaction_id (PK) - Unique transaction identifier
  • customer_id (FK) - Links to dim_customer
  • product_id (FK) - Links to products table
  • time_id (FK) - Links to dim_time
  • quantity - Number of items purchased
  • total_price - Transaction amount (MEASURE)
  • discount - Applied discount (MEASURE)
  • category - Product category

Why this design?
  - Enables fast aggregations (SUM, COUNT, AVG)
  - Supports drill-down and roll-up operations
  - Stores atomic-level transaction data

DIMENSION TABLE 1: dim_customer
───────────────────────────────
Purpose: Customer attributes for segmentation

Fields:
  • customer_id (PK)
  • customer_name
  • age_group - Demographic segment (18-25, 25-35, etc.)
  • location - Geographic dimension (Mumbai, Delhi, etc.)
  • customer_segment - Behavioral segment (Budget, Regular, Premium)
  • registration_date

Use Cases:
  - Customer segmentation analysis
  - Demographic-based recommendations
  - Location-based inventory planning

DIMENSION TABLE 2: dim_time
───────────────────────────
Purpose: Temporal analysis and time-based patterns

Fields:
  • time_id (PK)
  • timestamp
  • hour - Hour of day (0-23)
  • day - Day of month
  • month - Month (1-12)
  • year
  • day_of_week - Monday, Tuesday, etc.
  • is_weekend - Boolean flag (1/0)

Use Cases:
  - Seasonal trend analysis
  - Peak shopping hours identification
  - Weekend vs weekday patterns

PRODUCTS TABLE (Dimension-like)
───────────────────────────────
Fields:
  • id (PK)
  • name - Product name
  • category - Product category
  • price - Current price
  • img - Emoji representation
  • total_purchases - Popularity metric
  • keywords - For search functionality


================================================================================
                       MACHINE LEARNING ALGORITHMS USED
================================================================================

ALGORITHM 1: APRIORI ALGORITHM (Association Rule Mining)
═══════════════════════════════════════════════════════

Purpose: Market Basket Analysis - Find products frequently bought together
Algorithm Type: Unsupervised Learning (Association Rule Mining)
Implementation: Custom implementation in ml_models.py

HOW IT WORKS (Step-by-Step)
────────────────────────────

Step 1: Data Preparation
   Input: List of transactions from 38,765 grocery purchases
   Example:
   Transaction 1: [Bread, Butter, Milk]
   Transaction 2: [Bread, Cheese, Eggs]
   Transaction 3: [Bread, Butter, Cheese]

Step 2: Calculate Support
   Formula: Support(A) = Count(A) / Total Transactions
   
   Example:
   Bread appears in 15,000/38,765 transactions → Support = 38.7%
   
   Code:
   ```python
   item_counts[item] += 1
   support = item_counts[item] / total_transactions
   ```

Step 3: Filter Frequent Items
   Only keep items with support ≥ min_support (default: 1%)

Step 4: Generate Item Pairs
   Create all 2-item combinations from each transaction

Step 5: Calculate Confidence
   Formula: Confidence(A→B) = Support(A∪B) / Support(A)
   
   Interpretation: "If customer buys A, what's the probability they buy B?"
   
   Example:
   Bread→Butter appears in 12,750 transactions
   Bread appears in 15,000 transactions
   Confidence = 12,750/15,000 = 85%

Step 6: Calculate Lift
   Formula: Lift(A→B) = Confidence(A→B) / Support(B)
   
   Example:
   Confidence(Bread→Butter) = 85%
   Support(Butter) = 31%
   Lift = 85% / 31% = 2.74
   
   Lift Interpretation:
   • Lift > 1.0: Positive correlation (items bought together more than random)
   • Lift = 1.0: Independent (no correlation)
   • Lift < 1.0: Negative correlation

Step 7: Sort by Confidence
   Return top recommendations sorted by confidence score

RESULTS:
   Total Rules Generated: 4,588 association rules
   Average Confidence: 65.2%
   Average Lift: 1.8


ALGORITHM 2: K-MEANS CLUSTERING (Customer Segmentation)
════════════════════════════════════════════════════════

Purpose: Segment customers into Budget/Regular/Premium shoppers
Algorithm Type: Unsupervised Learning (Clustering)
Implementation: Rule-based with K-Means-inspired thresholds

HOW WE USE K-MEANS FOR CUSTOMER SEGMENTATION
─────────────────────────────────────────────

REAL-TIME CART-BASED SEGMENTATION:

Instead of traditional K-Means that requires historical data, we use a 
HYBRID APPROACH that combines K-Means concepts with rule-based thresholds:

Step 1: Feature Extraction from Cart
   Features calculated:
   • unique_products: Number of different items
   • total_spent: Sum of (price × quantity)
   • avg_price: total_spent / total_quantity
   • purchase_frequency: Number of items in cart

Step 2: Rule-Based Clustering (K-Means-Inspired Thresholds)
   We define 3 clusters (K=3) based on spending patterns:
   
   Cluster 0 - Budget Shoppers 💰:
   • total_spent < ₹300
   • Characteristics: Value-conscious, essential items only
   • Confidence: 85%
   
   Cluster 1 - Regular Shoppers 🛒:
   • total_spent: ₹300 - ₹800
   • Characteristics: Balanced spending, moderate variety
   • Confidence: 80%
   
   Cluster 2 - Premium Shoppers 👑:
   • total_spent > ₹800
   • Characteristics: High spending, diverse expensive items
   • Confidence: 90%

Step 3: Confidence Adjustment
   Adjust confidence based on:
   • Product diversity: +5% if > 8 unique items, -5% if < 3
   • Average price: Adjust segment if avg_price conflicts with total_spent
   
   Example:
   If total_spent suggests Budget but avg_price > ₹150:
   → Upgrade to Regular (buying fewer high-value items)

Step 4: Return Segment
   Output:
   • cluster_id: 0, 1, or 2
   • segment_name: Budget/Regular/Premium with emoji
   • confidence: 70-99%
   • metrics: All calculated features

WHY THIS APPROACH WORKS:
✓ No training data required (works for anonymous users)
✓ Real-time prediction based on current cart
✓ Interpretable (users understand why they're in a segment)
✓ K-Means concept (3 centroids based on spending tiers)
✓ Dynamic (changes as cart changes)

TRADITIONAL K-MEANS (What we also have):
For stored customer data, we also train a traditional K-Means model:
• Uses historical purchase data from database
• Features: unique_products, avg_transaction, total_spent, purchase_frequency
• StandardScaler for feature normalization
• Elbow method to find optimal K (auto-detected as K=3)
• Silhouette score: 0.179 (cluster quality metric)

CODE IMPLEMENTATION:
```python
def assign_customer_to_segment(self, cart_data):
    # Calculate features
    unique_products = len(set([item['id'] for item in cart_data]))
    total_spent = sum([item['price'] * item['quantity'] for item in cart_data])
    avg_price = total_spent / sum([item['quantity'] for item in cart_data])
    
    # Rule-based clustering
    if total_spent < 300:
        segment_name = 'Budget Shoppers 💰'
        cluster_id = 0
        confidence = 85
    elif total_spent < 800:
        segment_name = 'Regular Shoppers 🛒'
        cluster_id = 1
        confidence = 80
    else:
        segment_name = 'Premium Shoppers 👑'
        cluster_id = 2
        confidence = 90
    
    # Adjust based on product diversity
    if unique_products > 8:
        confidence = min(confidence + 5, 99)
    
    # Adjust based on average price
    if avg_price > 150 and segment_name == 'Budget Shoppers 💰':
        segment_name = 'Regular Shoppers 🛒'
        cluster_id = 1
    
    return {
        'cluster_id': cluster_id,
        'segment_name': segment_name,
        'confidence': confidence
    }
```


ALGORITHM 3: NAIVE BAYES CLASSIFIER (Age Group Prediction)
═══════════════════════════════════════════════════════════

Purpose: Predict customer age group based on shopping patterns
Algorithm Type: Supervised Learning (Probabilistic Classification)
Implementation: Custom Naive Bayes with category-based patterns

HOW WE USE NAIVE BAYES FOR AGE PREDICTION
──────────────────────────────────────────

PROBABILISTIC CLASSIFICATION BASED ON PRODUCT CATEGORIES:

Step 1: Extract Categories from Cart
   Get product categories for all items in cart
   Example cart: [Milk (dairy), Chips (snacks), Soda (beverages)]
   Categories: ['dairy', 'snacks', 'beverages']

Step 2: Define Age Group Patterns (Training Data)
   We create probability distributions for each age group:
   
   Age 18-25 (Young Adults):
   • snacks: 3.0 (high preference)
   • beverages: 2.5
   • instant: 2.0 (quick meals)
   • confectionery: 2.0
   • dairy: 1.0
   
   Age 25-35 (Young Professionals):
   • dairy: 2.5 (family shopping)
   • bakery: 2.0
   • vegetables: 2.0
   • meat: 1.8
   • snacks: 1.5
   
   Age 35-45 (Families):
   • vegetables: 3.0 (health-conscious)
   • fruit: 2.5
   • dairy: 2.5
   • meat: 2.0
   • organic: 2.0
   
   Age 45-60 (Mature Adults):
   • vegetables: 3.0
   • fruit: 3.0
   • organic: 2.5 (health focus)
   • dairy: 2.0
   • staples: 2.0

Step 3: Calculate Likelihood Scores (Naive Bayes)
   For each age group, calculate score:
   
   Score(age_group) = Σ (category_count × pattern_weight)
   
   Example for cart with [dairy(2), snacks(1), vegetables(1)]:
   
   Score(18-25) = 2×1.0 + 1×3.0 + 1×0.5 = 5.5
   Score(25-35) = 2×2.5 + 1×1.5 + 1×2.0 = 8.5  ← Highest
   Score(35-45) = 2×2.5 + 1×0.5 + 1×3.0 = 8.5
   Score(45-60) = 2×2.0 + 1×0.5 + 1×3.0 = 7.5

Step 4: Normalize to Probabilities
   Formula: P(age_group) = Score(age_group) / Σ(all_scores)
   
   Total = 5.5 + 8.5 + 8.5 + 7.5 = 30.0
   
   P(18-25) = 5.5/30.0 = 18.3%
   P(25-35) = 8.5/30.0 = 28.3%  ← Winner
   P(35-45) = 8.5/30.0 = 28.3%
   P(45-60) = 7.5/30.0 = 25.0%

Step 5: Select Top Prediction
   Winner: 25-35 age group (28.3% confidence)
   Return all probabilities for transparency

WHY NAIVE BAYES WORKS HERE:
✓ Assumes features (categories) are independent
✓ Fast computation (no training required)
✓ Probabilistic output (shows uncertainty)
✓ Interpretable (can see which categories influenced decision)
✓ Works with small data (pattern-based)

NAIVE BAYES ASSUMPTIONS:
• Each product category contributes independently to age prediction
• Category preferences are different across age groups
• P(Age|Categories) ∝ P(Categories|Age) × P(Age)

CODE IMPLEMENTATION:
```python
def predict_age_from_cart(self, categories):
    # Define age patterns
    age_patterns = {
        '18-25': {'snacks': 3.0, 'beverages': 2.5, ...},
        '25-35': {'dairy': 2.5, 'bakery': 2.0, ...},
        '35-45': {'vegetables': 3.0, 'fruit': 2.5, ...},
        '45-60': {'vegetables': 3.0, 'fruit': 3.0, ...}
    }
    
    # Calculate scores for each age group
    age_scores = {}
    for age_group, pattern in age_patterns.items():
        score = 0
        for category, count in Counter(categories).items():
            weight = pattern.get(category, 0.5)
            score += count * weight
        age_scores[age_group] = score
    
    # Normalize to probabilities
    total_score = sum(age_scores.values())
    probabilities = {
        age: (score / total_score * 100) 
        for age, score in age_scores.items()
    }
    
    # Get top prediction
    top_age = max(probabilities.items(), key=lambda x: x[1])
    
    return {
        'age_group': top_age[0],
        'confidence': round(top_age[1], 1),
        'probabilities': probabilities
    }
```


ALGORITHM 4: PATTERN RECOGNITION (Meal Intent Prediction)
══════════════════════════════════════════════════════════

Purpose: AI-powered prediction of user's meal preparation intent
Algorithm Type: Pattern Matching + Keyword-Based Classification
Implementation: Custom (server.py)

HOW IT WORKS:
─────────────

Step 1: Define Meal Patterns
   10 predefined patterns with keywords:
   
   Pattern: "Sandwich Time"
   Keywords: ['bread', 'butter', 'cheese', 'ham', 'lettuce']
   
   Pattern: "Breakfast Feast"
   Keywords: ['eggs', 'bacon', 'bread', 'milk', 'coffee']

Step 2: Calculate Match Scores
   For each pattern:
   - Count keyword matches in cart
   - Confidence = (matches / total_keywords) × 100
   
   Example:
   Cart: [Bread, Butter, Cheese, Lettuce]
   Sandwich Pattern: 4 matches / 6 keywords = 66.7%

Step 3: Rank and Return Top 3 Predictions

WHY IT WORKS:
✓ Provides context to recommendations
✓ Simple but effective pattern matching
✓ Fast real-time predictions


================================================================================
                          DATASET INFORMATION
================================================================================

SOURCE
──────
Dataset: Groceries Market Basket Dataset
Platform: Kaggle
URL: https://www.kaggle.com/datasets/heeraldedhia/groceries-dataset
License: Open Source

STATISTICS
──────────
Total Records: 38,765 transactions
Unique Products: 169 items
Time Period: 30 days of grocery store data
Members: 3,835 unique customers

DATA FIELDS
───────────
1. Member_number: Customer ID
2. Date: Transaction date (DD-MM-YYYY format)
3. itemDescription: Product name

DATA PREPROCESSING
──────────────────
1. Date parsing: Convert strings to datetime objects
2. Transaction grouping: Group items by Member_number
3. Product categorization: Map items to categories (dairy, bakery, snacks, etc.)
4. Price assignment: Random prices (₹20-₹200) as dataset lacks prices
5. Emoji mapping: Visual representation for products


================================================================================
                          HOW THE SYSTEM WORKS
================================================================================

USER INTERACTION FLOW
─────────────────────

1. User adds items to cart (e.g., Milk, Bread, Eggs)
   ↓
2. Frontend sends cart to backend
   ↓
3. Backend processes:
   a) Apriori: Finds products frequently bought with current cart
   b) K-Means: Segments user (Budget/Regular/Premium) based on total spending
   c) Naive Bayes: Predicts age group based on product categories
   d) Pattern Matching: Predicts meal intent
   ↓
4. Frontend displays:
   • Product recommendations with confidence scores
   • Customer segment badge with metrics
   • Age group prediction with probability distribution
   • Meal intent prediction
   • Hierarchical recommendation graph
   • Decision tree explanation
   ↓
5. User sees personalized AI insights in beautiful dashboard


AI INSIGHTS PAGE COMPONENTS (Top to Bottom)
────────────────────────────────────────────

1. Statistics Overview
   • Items analyzed
   • Total recommendations
   • Customers analyzed
   • Average confidence

2. Recommendation Graph (ReactFlow)
   • Multi-level hierarchical visualization
   • Color-coded by confidence (Red: 80%+, Cyan: 70-79%, Gray: <70%)
   • Interactive nodes showing product associations

3. Customer Segment Predictor (K-Means)
   • Segment badge: Budget 💰 / Regular 🛒 / Premium 👑
   • Confidence score with progress bar
   • Shopping metrics: Total spent, unique items, avg price
   • Gradient background based on segment

4. Age Group Predictor (Naive Bayes)
   • Primary age prediction with emoji (🎓 🏢 👨‍👩‍👧 👴)
   • Confidence percentage
   • Probability distribution for all age groups
   • Algorithm explanation

5. Meal Intent Predictor
   • Primary meal prediction (🥪 🍳 🍝 etc.)
   • Alternative predictions
   • Confidence scores

6. Decision Flow Tree
   • 4-step process explanation
   • Cart analysis → Pattern finding → Confidence filtering → Final picks


================================================================================
                        WHY THIS APPROACH WORKS
================================================================================

DATA MINING PERSPECTIVE
───────────────────────

1. APRIORI (Association Rules)
   ✓ Discovers hidden patterns in 38,765 transactions
   ✓ No labeled data required (unsupervised)
   ✓ Interpretable results (easy to explain to business)
   ✓ 4,588 rules with avg 65% confidence

2. K-MEANS (Customer Segmentation)
   ✓ Real-time segmentation without historical data
   ✓ Rule-based approach inspired by K-Means clustering
   ✓ Works for anonymous users
   ✓ Dynamic (changes with cart)

3. NAIVE BAYES (Age Prediction)
   ✓ Probabilistic classification
   ✓ Pattern-based (no training needed)
   ✓ Shows uncertainty through probabilities
   ✓ Fast real-time inference

DATA WAREHOUSE PERSPECTIVE
───────────────────────────

1. STAR SCHEMA DESIGN
   ✓ Optimized for analytical queries
   ✓ Fast aggregations (OLAP operations)
   ✓ Simple joins (better performance)

2. DIMENSIONAL MODELING
   ✓ Supports drill-down and roll-up
   ✓ Time-based analysis
   ✓ Customer-based analysis


================================================================================
                        POTENTIAL INTERVIEW QUESTIONS
================================================================================

BASIC LEVEL
───────────

Q1: What algorithms did you use and why?
A: 1. Apriori - Association rule mining for product recommendations
   2. K-Means - Customer segmentation (Budget/Regular/Premium)
   3. Naive Bayes - Age group prediction from shopping patterns
   4. Pattern Matching - Meal intent detection

Q2: Explain how K-Means segments customers in your project.
A: We use a hybrid approach:
   - Extract features: total_spent, unique_products, avg_price
   - Define 3 clusters with spending thresholds:
     * Budget: < ₹300
     * Regular: ₹300-₹800
     * Premium: > ₹800
   - Adjust confidence based on product diversity and avg price
   - Real-time prediction without requiring training data

Q3: How does Naive Bayes predict age groups?
A: 1. Extract product categories from cart (dairy, snacks, etc.)
   2. Match against age group patterns (18-25 prefers snacks, 45-60 prefers vegetables)
   3. Calculate likelihood score for each age group
   4. Normalize to probabilities using Bayes theorem
   5. Return top prediction with confidence and full probability distribution

Q4: What is the difference between supervised and unsupervised learning in your project?
A: Unsupervised: Apriori (no labels), K-Means (no training data)
   Supervised-style: Naive Bayes (pattern-based classification)
   Hybrid: Pattern matching (rule-based)


INTERMEDIATE LEVEL
──────────────────

Q5: Why use rule-based K-Means instead of traditional K-Means?
A: Traditional K-Means requires:
   - Historical purchase data for each user
   - Training phase
   - User login/tracking
   
   Our approach:
   ✓ Works for anonymous users
   ✓ Real-time prediction
   ✓ No training needed
   ✓ Interpretable (users see why they're in a segment)
   ✓ K-Means-inspired (3 centroids based on spending)

Q6: How does your Naive Bayes differ from standard implementations?
A: Standard Naive Bayes:
   - Requires labeled training data
   - Learns from examples
   - Uses frequency-based probabilities
   
   Our approach:
   ✓ Pattern-based (expert knowledge)
   ✓ No training data needed
   ✓ Works immediately
   ✓ Domain-specific (grocery shopping patterns)
   ✓ Transparent reasoning

Q7: How do you handle data sparsity in Apriori?
A: - Use low min_support (1%) to catch infrequent patterns
   - 38,765 transactions provide enough data
   - Focus on 2-item rules (avoid combinatorial explosion)
   - Filter by confidence (30%) to ensure quality


ADVANCED LEVEL
──────────────

Q8: How would you improve the K-Means segmentation?
A: Improvements:
   1. Add temporal features (time since first purchase, recency)
   2. Use actual K-Means on historical data for logged-in users
   3. Implement RFM analysis (Recency, Frequency, Monetary)
   4. Silhouette analysis to find optimal K automatically
   5. Persist cluster assignments in database

Q9: What are limitations of your Naive Bayes approach?
A: Limitations:
   ✗ Assumes category independence (not always true)
   ✗ Pattern-based, not learned from data
   ✗ May not capture complex relationships
   ✗ Predefined age groups (not personalized)
   
   Solutions:
   ✓ Train on actual purchase data if available
   ✓ Use ensemble with other classifiers
   ✓ Implement confidence thresholds
   ✓ Update patterns based on trends

Q10: How do you measure the accuracy of your ML models?
A: Apriori: Confidence (65% avg), Lift (1.8 avg), Support
   K-Means: Silhouette score (0.179), cluster separation
   Naive Bayes: Confidence scores, probability distributions
   Overall: User engagement (CTR, conversion rate) via A/B testing


================================================================================
                            PROJECT SUMMARY
================================================================================

WHAT WE BUILT
─────────────
An end-to-end AI-powered e-commerce recommendation system that:
✓ Uses real-world grocery transaction data (38,765 records)
✓ Implements data warehousing with star schema
✓ Applies 4 ML algorithms (Apriori, K-Means, Naive Bayes, Pattern Matching)
✓ Provides real-time product recommendations
✓ Segments customers into Budget/Regular/Premium
✓ Predicts customer age group (18-25, 25-35, 35-45, 45-60)
✓ Predicts meal intent
✓ Visualizes decision-making with interactive graphs

KEY FEATURES
────────────
• Association Rule Mining: 4,588 rules for product recommendations
• Customer Segmentation: Real-time K-Means-based classification
• Age Prediction: Naive Bayes with probabilistic output
• Meal Intent: Pattern-based prediction
• Interactive Dashboard: Beautiful AI insights visualization
• Hierarchical Graphs: Multi-level recommendation trees
• Decision Trees: Step-by-step explanation of recommendations

DATA WAREHOUSE
──────────────
• Star Schema with 1 fact table + 3 dimension tables
• OLAP operations: Roll-up, Drill-down, Slice, Dice
• ETL pipeline for data loading
• Support for analytical queries

BUSINESS VALUE
──────────────
• Increase average order value through cross-selling
• Personalized shopping experience
• Customer insights for marketing
• Data-driven inventory decisions
• Automated recommendation generation

================================================================================
                              END OF DOCUMENT
================================================================================

Generated on: October 29, 2025
Project: SmartCart - AI-Powered Recommendation System
Updated with: K-Means Customer Segmentation & Naive Bayes Age Prediction

For technical details, refer to:
• backend/ml_models.py - ML algorithm implementations
• backend/server.py - API endpoints
• src/App.js - Frontend components
